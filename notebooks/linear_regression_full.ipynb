{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn: regresión lineal\n",
    "\n",
    "En este notebook, entrenaremos un modelo simple de regresión lineal a partir de un dataset de rendimiento de estudiantes.\n",
    "\n",
    "Se trata de uno de los modelos más simples, pero los pasos que se utilizan para entrenarlo son prácticamente idénticas para otros muchos modelos de aprendizaje supervisado (tanto de regresión, como de clasificación y clustering).\n",
    "\n",
    "A partir de lo aprendido aquí, podríamos ejecutar otros modelos como _Regresión polinómica_, _SVM_ o _Random Forests_ inmediatamente sobre el mismo dataset (por supuesto, hay que tener cuidado con el _overfitting_!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, importamos todo lo que vamos a necesitar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y leemos el dataset\n",
    "DATA_FOLDER = os.path.join(\"..\", \"data\")\n",
    "FILENAME = \"student_performance.csv\"\n",
    "df = pd.read_csv(os.path.join(DATA_FOLDER, FILENAME))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La variable que queremos predecir es \"Performance Index\"\n",
    "df['Performance Index'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existen variables que claramente ayudarán a predecir el performance index, como el número de horas de estudio\n",
    "df['Hours Studied'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracurricular activities es una variable booleana (Si/No), aunque está en formato de string, luego veremos\n",
    "# como tratarla\n",
    "df['Extracurricular Activities'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de los datos\n",
    "- La variable ```Performance Index``` es la que queremos predecir (variable objetivo). Para ello, usaremos el resto de variables del dataset en la medida de lo posible.\n",
    "- Vamos a hacer algunos plots para ver que variables podrían ser más interesantes a simple vista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Hours Studied'], df['Performance Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Previous Scores'], df['Performance Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = df.drop(\"Extracurricular Activities\", axis = 1)\n",
    "correl = corr_data.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correl, annot=True, cmap=\"viridis\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo lineal\n",
    "- Claramente, `Previous Score` es la columna más importante\n",
    "- También hay algo de correlación con `Hours Studied`\n",
    "- El resto de columnas no tienen prácticamente correlación, asi que no merece la pena incluirlas en un modelo lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En primer lugar, dividimos los datos en variables explicativas y variable objetivo (X e y)\n",
    "X = df[['Hours Studied', 'Previous Scores']]\n",
    "y = df[\"Performance Index\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y hacemos un train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También es necesario escalar los datos para centrarlos en torno al 0, lo cuál mejora el rendimiento del modelo\n",
    "# Haciendo que ninguna variable sea más importante que otras por su escala\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "np.random.seed(42)\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y sacamos las predicciones para el conjunto de prueba\n",
    "y_pred = linear_reg.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos calcular el R² para ver la precisión del modelo\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y ahora podemos plottear los valores predecidos frente a los reales\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_pred), max(y_pred)], 'r--')\n",
    "plt.xlabel(\"Valores reales\")\n",
    "plt.ylabel(\"Valores predecidos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O un histograma de los residuos\n",
    "residuals = y_pred - y_test\n",
    "plt.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(\"Residuos\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "- Podemos agilizar el proceso de entrenamiento usando `Pipeline`\n",
    "- Especificamos todos los pasos y solo ejecutamos un `fit()` y un `predict()`\n",
    "- Muy útil para procesos más complicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Hours Studied', 'Previous Scores', 'Sleep Hours']]\n",
    "y = df[\"Performance Index\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajar con datos categóricos\n",
    "\n",
    "- Por último, vamos a entrenar un modelo usando también las otras variables y la variable categórica\n",
    "- Para ello, usamos `pd.get_dummies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso # Otro modelo lineal, con regularización añadida\n",
    "X = df.drop(columns='Performance Index')\n",
    "y = df[\"Performance Index\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"regressor\", Lasso())\n",
    "])\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_python_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
